## üöÄ Awesome-Diffusion-Guidance [![Awesome](https://awesome.re/badge.svg)](https://github.com/sindresorhus/awesome)

 **Welcome to the collection of research on diffusion guidance methods!**  
This repo curates cutting-edge papers on diffusion model guidance üåü

Your stars fuel the updates! ‚≠ê This library is actively maintained, with new papers and features added regularly.
## Table of Contents
- [üöÄ Awesome-Diffusion-Guidance ](#-awesome-diffusion-guidance-)
- [Table of Contents](#table-of-contents)
  - [Papers](#papers)
  - [How to Contributeüìù](#how-to-contribute)
  - [To Do](#to-do)
  
### Papers
| Title | Code | Date | Publication | Summary |
| --------------------------------------------------------------------- | ---------------------------------------------------------- | ---------- | ----------- | ----------- |
| [**Diffusion Models Beat GANs on Image Synthesis**](https://proceedings.neurips.cc/paper/2021/hash/49ad23d1ec9fa4bd8d77d02681df5cfa-Abstract.html) | [Code](https://github.com/openai/guided-diffusion) | 2021.12 | NeurIPS 2021 | Introduces classifier guidance using gradients to enhance sample quality in diffusion models, surpassing GANs on image synthesis. |
| [**Classifier-Free Diffusion Guidance**](https://openreview.net/forum?id=qw8AKxfYbI) | N/A | 2021.12 | NeurIPS 2021 Workshop | Enables guidance without classifiers by jointly training on conditional and unconditional objectives. |
| [**Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models**](https://dl.acm.org/doi/abs/10.1145/3592116) | N/A | 2023.01 | ACM Transactions on Graphics | Introduces Attend-and-Excite, an attention-based semantic guidance method that iteratively refines cross-attention maps to ensure text-to-image diffusion models faithfully generate all subjects in the prompt (requires new attention processor per model). |
| [**Universal Guidance for Diffusion Models**](https://ieeexplore.ieee.org/document/10208653/) | [Code](https://github.com/arpitbansal297/Universal-Guided-Diffusion) | 2023.06 | CVPRW2023 | Provides a training-free method to incorporate arbitrary conditions into pre-trained unguided diffusion models using energy functions. |
| [**Improving Sample Quality of Diffusion Models Using Self-Attention Guidance**](https://ieeexplore.ieee.org/document/10378223/) | [Code](https://github.com/SusungHong/Self-Attention-Guidance) | 2023.10 | ICCV2023 | Uses self-attention maps to guide diffusion models away from degraded regions, improving generated image quality without extra training. |
| [**Characteristic Guidance: Non-linear Correction for Diffusion Model at Large Guidance Scale**](https://proceedings.mlr.press/v235/zheng24f.html) | [Code](https://github.com/scraed/CharacteristicGuidanceWebUI) | 2023.12 | ICML 2024 | Applies non-linear corrections based on Fokker-Plank equations to handle over-saturation artifact at large guidance scales in diffusion models. |
| [**Adaptive Guidance: Training-free Acceleration of Conditional Diffusion Models**](https://arxiv.org/abs/2312.12487) | N/A | 2023.12 | AAAI 2025 | Skips evaluations upon convergence via NAS policies for training-free acceleration reducing NFEs. |
| [**ProtoDiffusion: Classifier-Free Diffusion Guidance with Prototype Learning**](https://proceedings.mlr.press/v222/baykal24a.html) | [Code](https://github.com/ituvisionlab/ProtoDiffusion) | 2024.02 | ACML 2024 | Integrates prototype learning into classifier-free guidance to speed up sampling and enhance quality using class-specific prototypes. |
| [**Self-Rectifying Diffusion Sampling with Perturbed-Attention Guidance**](https://arxiv.org/abs/2403.17377) | [Code](https://github.com/cvlab-kaist/Perturbed-Attention-Guidance) | 2024.03 | ECCV 2024 | Proposes Perturbed-Attention Guidance (PAG) to improve sample quality in diffusion models by adding random perturbations to attention maps, enabling self-rectification in both unconditional and conditional generation. |
| [**Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models**](https://arxiv.org/abs/2404.07724) | [Code](https://github.com/kynkaat/guidance-interval) | 2024.04 | NeurIPS 2024 | Restricts classifier-free guidance to a limited noise level interval during sampling, improving inference speed and result quality. |
| [**CFG++: Manifold-constrained Classifier Free Guidance for Diffusion Models**](http://arxiv.org/abs/2406.08070) | [Code](https://cfgpp-diffusion.github.io/) | 2024.06 | ICLR 2025 | Constrains guidance to data manifold using orthogonal projections for better sample quality and invertibility. |
| [**Guiding a Diffusion Model with a Bad Version of Itself**](https://proceedings.neurips.cc/paper_files/paper/2024/hash/5ee7ed60a7e8169012224dec5fe0d27f-Abstract-Conference.html) | [Code](https://github.com/NVlabs/edm2) | 2024.06 | NeurIPS 2024 | Uses a poorly trained model version for guidance to control trade-offs between sample quality and diversity. |
| [**No Training, No Problem: Rethinking Classifier-Free Guidance for Diffusion Models**](https://arxiv.org/abs/2407.02687) | N/A | 2024.07 | ICLR 2025 | Introduces independent condition guidance (ICG) and time-step guidance (TSG) using time-step encodings for training-free, invertible sampling applicable unconditionally. |
| [**Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention**](https://arxiv.org/abs/2408.00760) | [Code](https://github.com/SusungHong/SEG-SDXL) | 2024.08 | NeurIPS 2024 | Presents Smoothed Energy Guidance (SEG), a method that smooths energy curvature in attention maps to enhance unconditional image generation quality while minimizing artifacts (requires new attention processor per model). |
| [**Eliminating Oversaturation and Artifacts of High Guidance Scales in Diffusion Models**](https://arxiv.org/pdf/2410.02416) | [Code](https://github.com/huggingface/diffusers/issues/9585#issuecomment-2774216484) | 2024.10 | ICLR 2025 | Decompose the update term in CFG into parallel and orthogonal components with respect to the conditional model prediction and observe that the parallel component primarily causes oversaturation, while the orthogonal component enhances image quality. |
| [**Spatiotemporal Skip Guidance for Enhanced Video Diffusion Sampling**](https://arxiv.org/abs/2411.18664) | [Code](https://github.com/junhahyung/STGuidance) | 2024.11 | CVPR 2025 | Develops Spatiotemporal Skip Guidance (STG), a training-free technique that skips specific layers in video diffusion transformers to boost sample quality without sacrificing diversity or motion dynamics. |
| [**TFG: Unified Training-Free Guidance for Diffusion Models**](https://papers.nips.cc/paper_files/paper/2024/hash/2818054fc6de6dacdda0f142a3475933-Abstract-Conference.html) | [Code](https://github.com/YWolfeee/Training-Free-Guidance) | 2024.09 | NeurIPS 2024 | Unifies training-free guidance methods with efficient hyper-parameter optimization for various conditional generation tasks. |
| [**TFG-Flow: Training-free Guidance in Multimodal Generative Flow**](https://arxiv.org/abs/2501.14216) | N/A | 2025.01 | ICLR 2025 | Introduces a novel training-free guidance method for multimodal generative flow, uniquely addressing the curse-of-dimensionality while maintaining unbiased sampling for guiding discrete variables in applications like molecular design. |
| [**REG: Rectified Gradient Guidance for Conditional Diffusion Models**](https://arxiv.org/abs/2501.18865) | N/A | 2025.01 | ICML 2025 | Proposes a rectified gradient guidance method that enhances conditional diffusion models by aligning practical implementations with a theoretically valid scaled joint distribution objective, improving performance over existing guidance techniques. |
| [**Variational Control for Guidance in Diffusion Models**](https://arxiv.org/abs/2502.03686) | [Code](https://github.com/czi-ai/oc-guidance) | 2025.02 | ArXiv | Employs variational inference for terminal cost guidance in pre-trained models, unifying methods for training-free inverse problems. |
| [**Classifier-Free Guidance: From High-Dimensional Analysis to Generalized Guidance Forms**](https://arxiv.org/abs/2502.07849) | N/A | 2025.02 | ArXiv | Uniquely demonstrates that Classifier-Free Guidance accurately reproduces the target distribution in high and infinite dimensions, extending to a family of non-linear generalizations with improved robustness, sample fidelity, and diversity. |
| [**Classifier-free Guidance with Adaptive Scaling**](https://arxiv.org/abs/2502.10574) | N/A | 2025.02 | ArXiv | Œ≤-CFG introduces a novel adaptive scaling method using gradient-based normalization and time-dependent Œ≤-distribution curves to dynamically balance prompt matching and image quality during the diffusion denoising process. |
| [**Diffusion Models without Classifier-free Guidance**](https://arxiv.org/abs/2502.12154) | [Code](https://github.com/tzco/Diffusion-wo-CFG) | 2025.02 | ArXiv | Integrates condition posteriors into objectives for accelerated processes matching CFG quality without unconditional models. |
| [**Improving Discriminator Guidance in Diffusion Models**](https://arxiv.org/abs/2503.16117) | N/A | 2025.03 | ArXiv | Proposes a training objective for discriminator guidance in diffusion models that minimizes Kullback-Leibler divergence, improving sample quality over the conventional method using Cross-Entropy loss. |
| [**Guidance Free Image Editing via Explicit Conditioning**](https://arxiv.org/abs/2503.17593) | N/A | 2025.03 | ArXiv | Explicit  Proposes a  technique that models noise distribution on input modalities to guide conditional diffusion models, significantly reducing computational costs and improving inference time compared to CFG in image editing tasks. |
| [**TCFG: Tangential Damping Classifier-free Guidance**](https://arxiv.org/abs/2503.18137) | [Code](https://github.com/5410tiffany/tcfg.github.io) | 2025.03 | CVPR 2025 | Geometrically filters tangential misalignments using SVD for better manifold alignment and quality with minimal overhead. |
| [**CFG-Zero\*: Improved Classifier-Free Guidance for Flow Matching Models**](https://arxiv.org/abs/2503.18886) | [Code](https://github.com/WeichenFan/CFG-Zero-star) | 2025.03 | ArXiv | Optimizes guidance scales for flow matching to correct early velocities and zero initial steps, outperforming CFG in multimedia generation. |
| [**Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion Model**](https://arxiv.org/abs/2504.01521) | N/A | 2025.04 | ICLR 2025 | Introduces a simple transfer approach that leverages pre-trained knowledge to guide the sampling process toward the target domain, sharing a formulation similar to classifier-free guidance for improved domain alignment and generation quality. |
| [**Entropy Rectifying Guidance for Diffusion and Flow Models**](https://arxiv.org/abs/2504.13987) | N/A | 2025.04 | ArXiv | Entropy Rectifying Guidance (ERG) is a simple and effective guidance mechanism that improves image quality, diversity, and prompt consistency in diffusion and flow models by modifying the attention mechanism during inference, extending to unconditional sampling and combining seamlessly with other guidance methods. |
| [**Instructing Text-to-Image Diffusion Models via Classifier-Guided Semantic Optimization**](https://arxiv.org/abs/2505.14254) | N/A | 2025.05 | ArXiv | Proposes optimizing semantic embeddings guided by attribute classifiers to steer text-to-image diffusion models for desired edits, eliminating the need for text prompts and model training or fine-tuning. |
| [**Diffusion Models with Double Guidance: Generate with aggregated datasets**](https://arxiv.org/abs/2505.13213) | N/A | 2025.05 | ArXiv | Enables precise conditional generation by maintaining control over multiple conditions without requiring joint annotations, even when training samples lack all conditions simultaneously. |
| [**Adaptive Diffusion Guidance via Stochastic Optimal Control**](https://arxiv.org/abs/2505.19367) | N/A | 2025.05 | ArXiv | Introduces a stochastic optimal control framework that dynamically adjusts guidance strength in diffusion models based on time, current sample, and conditioning class, offering a principled approach to guidance scheduling. |
| [**Conditional Diffusion Models with Classifier-Free Gibbs-like Guidance**](https://arxiv.org/abs/2505.21101) | [Code](https://github.com/yazidjanati/cfgig) | 2025.05 | ArXiv | Samples tilted distributions with R√©nyi divergence for low-noise corrections, fixing CFG's diversity issues. |
| [**Normalized Attention Guidance: Universal Negative Guidance for Diffusion Model**](https://arxiv.org/abs/2505.21179) | N/A | 2025.05 | ArXiv | Introduces a training-free, universal negative guidance method for diffusion models that uses extrapolation in attention space with L1-based normalization, generalizing across architectures, sampling regimes, and modalities while maintaining fidelity. |
| [**Angle Domain Guidance: Latent Diffusion Requires Rotation Rather Than Extrapolation**](https://arxiv.org/abs/2506.11039) | [Code](https://github.com/jinc7461/ADG) | 2025.06 | ICML 2025 | Angle Domain Guidance (ADG) mitigates color distortions in text-to-image latent diffusion models by constraining magnitude variations and optimizing angular alignment, preserving enhanced text-image alignment at higher guidance weights. |
| [**Feedback Guidance of Diffusion Models**](https://arxiv.org/abs/2506.06085) | [Code](https://github.com/FelixKoulischer/FBG_using_edm2) | 2025.06 | ArXiv | Self-regulates coefficients based on predicted informativeness, adapting for complex prompts and balancing diversity-quality. |
| [**How Much To Guide: Revisiting Adaptive Guidance in Classifier-Free Guidance Text-to-Vision Diffusion Models**](https://arxiv.org/abs/2506.08351) | N/A | 2025.06 | ArXiv | Step AG, a simple and universally applicable adaptive guidance strategy, restricts classifier-free guidance to the first several denoising steps, achieving high-quality, well-conditioned images with a 20% to 30% speedup. |
| [**Token Perturbation Guidance for Diffusion Models**](https://arxiv.org/abs/2506.10036) | [Code](https://github.com/TaatiTeam/Token-Perturbation-Guidance) | 2025.06 | ArXiv | Shuffles tokens for training-free, condition-agnostic guidance improving unconditional generation. |
| [**S¬≤-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models**](https://arxiv.org/abs/2508.12880) | [Code](https://github.com/AMAP-ML/S2-Guidance) | 2025.08 | ArXiv | Introduces a training-free self-guidance method using stochastic block-dropping to create sub-networks that refine suboptimal predictions, enhancing sample quality and prompt adherence beyond traditional CFG. |

### How to Contributeüìù
If you have any relevant papers to add, please follow the guidelines below:
1. Fork the repository.
2. Create a new branch for your changes.
3. Add your paper details in the paper section.
4. Commit and push your changes.
5. Open a pull request for review.


### To Do
Will update this repository by categorizing the papers.

